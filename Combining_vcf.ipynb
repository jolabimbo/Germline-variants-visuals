{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2800f3-16bd-4b29-bd31-3b1accc5f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üß© Step 1: Combine Annotated TXT Files into a Single CSV\n",
    "This script reads all .txt files in a specified folder \n",
    "(e.g., output/ or output_03/), extracts the sample ID \n",
    "from the filename, and concatenates the data into a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb31d94-dba5-43f7-adc8-798d34fa0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "folder = Path(\"")\n",
    "\n",
    "dfs = []\n",
    "for f in folder.glob(\"*txt\"):\n",
    "    if f.is_file():\n",
    "        df = pd.read_csv(f, sep=\"\\t\", dtype=str)\n",
    "        match = re.match(r\"(\\d+)_\", f.name)\n",
    "        file_id = match.group(1) if match else f.stem.split(\"_\")[0]\n",
    "        df.insert(0, \"ID\", file_id)\n",
    "        dfs.append(df)\n",
    "\n",
    "pd.concat(dfs, ignore_index=True).to_csv(\"combined_Batch1.csv\", index=False)"
   ]

    "##Optional! Combining vcf but with error handling incorporated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc77f8-524b-482d-93a6-62171f40fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "##################\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "folder = Path(\"")\n",
    "\n",
    "dfs = []\n",
    "for f in folder.glob(\"*txt\"):\n",
    "    if f.is_file():\n",
    "        print(f\"Processing file: {f.name}\")\n",
    "        df = pd.read_csv(f, sep=\"\\t\", dtype=str)\n",
    "        match = re.match(r\"(\\d+)_\", f.name)\n",
    "        file_id = match.group(1) if match else f.stem.split(\"_\")[0]\n",
    "        df.insert(0, \"ID\", file_id)\n",
    "        dfs.append(df)\n",
    "\n",
    "if dfs:\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    combined.to_csv(\"combined.csv\", index=False)\n",
    "    print(f\"Combined CSV written with shape: {combined.shape}\")\n",
    "else:\n",
    "    print(\"No .txt files found in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626e96a5-1161-4433-b60b-63fd6e485ef2",
   "metadata": {},
   "outputs": [
    {

   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c18063",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combining normalized vcf files into a combined vcf. Annovar scattered the \n",
    "# orientation of the reference and alternate alleles, using the normalized to replace\n",
    "#reference and alternate alleles in the final csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795135ec-a4a0-4da1-8dd4-3824051186f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import gzip\n",
    "import io\n",
    "\n",
    "folder = Path(\"")\n",
    "\n",
    "vcf_dfs = []\n",
    "\n",
    "for f in folder.glob(\"*normalized.vcf.gz\"):\n",
    "    print(f\"Processing zipped VCF: {f.name}\")\n",
    "    \n",
    "    with gzip.open(f, \"rt\") as fh:\n",
    "        lines = [line for line in fh if not line.startswith(\"##\")]\n",
    "    \n",
    "    if not lines:\n",
    "        print(f\"‚ö†Ô∏è Skipping empty VCF: {f.name}\")\n",
    "        continue\n",
    "\n",
    "    header_line = next((line for line in lines if line.startswith(\"#CHROM\")), None)\n",
    "    data_lines = [line for line in lines if not line.startswith(\"#\")]\n",
    "\n",
    "    if header_line and data_lines:\n",
    "        columns = header_line.strip().lstrip(\"#\").split(\"\\t\")\n",
    "        vcf_df = pd.read_csv(io.StringIO(\"\".join(data_lines)), sep=\"\\t\", names=columns, dtype=str)\n",
    "        \n",
    "        # Extract sample ID from filename (e.g., 123_normalized.vcf.gz ‚Üí 123)\n",
    "        match = re.match(r\"(\\d+)_\", f.name)\n",
    "        file_id = match.group(1) if match else f.stem.split(\"_\")[0]\n",
    "        \n",
    "        vcf_df.insert(0, \"Sample_ID\", file_id)\n",
    "        vcf_dfs.append(vcf_df)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No usable content in: {f.name}\")\n",
    "\n",
    "# Save the combined VCF table\n",
    "if vcf_dfs:\n",
    "    combined_Batch1vcf = pd.concat(vcf_dfs, ignore_index=True)\n",
    "    out_path = folder / \"combined_Batch1vcf.csv\"\n",
    "    combined_Batch1vcf.to_csv(out_path, index=False)\n",
    "    print(f\"‚úÖ Combined zipped VCF saved to:\\n{out_path}\\nShape: {combined_Batch1vcf.shape}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid zipped VCF files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f3e94-3581-439a-aa15-0837bf3e387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Both merged batches have similar IDs so i need to change to original sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3934825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ID values replaced with names using mapping.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the main file with plate numbers\n",
    "main_df = pd.read_csv(\"")\n",
    "\n",
    "# Load the mapping file that maps Plate_No to Sample_ID\n",
    "mapping_df = pd.read_csv(\"C:/Users/LENOVO/Documents/ONCO50/sample_name.csv\")\n",
    "\n",
    "# Create a dictionary: ID ‚Üí Name\n",
    "id_to_name = mapping_df.set_index(\"ID\")[\"NAME\"].to_dict()\n",
    "\n",
    "# Replace values in the main dataframe's ID column\n",
    "main_df[\"ID\"] = main_df[\"ID\"].map(id_to_name).fillna(main_df[\"ID\"])  # fallback if no match\n",
    "\n",
    "# Save result\n",
    "main_df.to_csv(\"vcf_with_named_ids.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ ID values replaced with names using mapping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158091cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ""
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac92f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
