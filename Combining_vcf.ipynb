{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2800f3-16bd-4b29-bd31-3b1accc5f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üß© Step 1: Combine Annotated TXT Files into a Single CSV\n",
    "This script reads all .txt files in a specified folder \n",
    "(e.g., output/ or output_03/), extracts the sample ID \n",
    "from the filename, and concatenates the data into a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb31d94-dba5-43f7-adc8-798d34fa0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "folder = Path(\"C:/Users/LENOVO/Documents/ONCO50_PMS2_REANALYSIS/output_03\")\n",
    "\n",
    "dfs = []\n",
    "for f in folder.glob(\"*txt\"):\n",
    "    if f.is_file():\n",
    "        df = pd.read_csv(f, sep=\"\\t\", dtype=str)\n",
    "        match = re.match(r\"(\\d+)_\", f.name)\n",
    "        file_id = match.group(1) if match else f.stem.split(\"_\")[0]\n",
    "        df.insert(0, \"ID\", file_id)\n",
    "        dfs.append(df)\n",
    "\n",
    "pd.concat(dfs, ignore_index=True).to_csv(\"combined_Batch1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6378015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Desktop\\Python_Learn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c613a0-fcf6-4e21-9d5a-d588d42ead0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Optional! Combining vcf but with error handling incorporated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc77f8-524b-482d-93a6-62171f40fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 10_S10_annotated.hg19_multianno.txt\n",
      "Processing file: 11_S11_annotated.hg19_multianno.txt\n",
      "Processing file: 12_S12_annotated.hg19_multianno.txt\n",
      "Processing file: 13_S13_annotated.hg19_multianno.txt\n",
      "Processing file: 14_S14_annotated.hg19_multianno.txt\n",
      "Processing file: 15_S15_annotated.hg19_multianno.txt\n",
      "Processing file: 16_S16_annotated.hg19_multianno.txt\n",
      "Processing file: 17_S17_annotated.hg19_multianno.txt\n",
      "Processing file: 18_S18_annotated.hg19_multianno.txt\n",
      "Processing file: 19_S19_annotated.hg19_multianno.txt\n",
      "Processing file: 1_S1_annotated.hg19_multianno.txt\n",
      "Processing file: 20_S20_annotated.hg19_multianno.txt\n",
      "Processing file: 21_S21_annotated.hg19_multianno.txt\n",
      "Processing file: 22_S22_annotated.hg19_multianno.txt\n",
      "Processing file: 23_S23_annotated.hg19_multianno.txt\n",
      "Processing file: 24_S24_annotated.hg19_multianno.txt\n",
      "Processing file: 25_S25_annotated.hg19_multianno.txt\n",
      "Processing file: 26_S26_annotated.hg19_multianno.txt\n",
      "Processing file: 27_S27_annotated.hg19_multianno.txt\n",
      "Processing file: 28_S28_annotated.hg19_multianno.txt\n",
      "Processing file: 29_S29_annotated.hg19_multianno.txt\n",
      "Processing file: 2_S2_annotated.hg19_multianno.txt\n",
      "Processing file: 30_S30_annotated.hg19_multianno.txt\n",
      "Processing file: 31_S31_annotated.hg19_multianno.txt\n",
      "Processing file: 32_S32_annotated.hg19_multianno.txt\n",
      "Processing file: 33_S33_annotated.hg19_multianno.txt\n",
      "Processing file: 34_S34_annotated.hg19_multianno.txt\n",
      "Processing file: 35_S35_annotated.hg19_multianno.txt\n",
      "Processing file: 36_S36_annotated.hg19_multianno.txt\n",
      "Processing file: 37_S37_annotated.hg19_multianno.txt\n",
      "Processing file: 38_S38_annotated.hg19_multianno.txt\n",
      "Processing file: 39_S39_annotated.hg19_multianno.txt\n",
      "Processing file: 3_S3_annotated.hg19_multianno.txt\n",
      "Processing file: 40_S40_annotated.hg19_multianno.txt\n",
      "Processing file: 41_S41_annotated.hg19_multianno.txt\n",
      "Processing file: 42_S42_annotated.hg19_multianno.txt\n",
      "Processing file: 43_S43_annotated.hg19_multianno.txt\n",
      "Processing file: 44_S44_annotated.hg19_multianno.txt\n",
      "Processing file: 45_S45_annotated.hg19_multianno.txt\n",
      "Processing file: 46_S46_annotated.hg19_multianno.txt\n",
      "Processing file: 47_S47_annotated.hg19_multianno.txt\n",
      "Processing file: 48_S48_annotated.hg19_multianno.txt\n",
      "Processing file: 49_S49_annotated.hg19_multianno.txt\n",
      "Processing file: 4_S4_annotated.hg19_multianno.txt\n",
      "Processing file: 50_S50_annotated.hg19_multianno.txt\n",
      "Processing file: 51_S51_annotated.hg19_multianno.txt\n",
      "Processing file: 52_S52_annotated.hg19_multianno.txt\n",
      "Processing file: 53_S53_annotated.hg19_multianno.txt\n",
      "Processing file: 54_S54_annotated.hg19_multianno.txt\n",
      "Processing file: 55_S55_annotated.hg19_multianno.txt\n",
      "Processing file: 56_S56_annotated.hg19_multianno.txt\n",
      "Processing file: 57_S57_annotated.hg19_multianno.txt\n",
      "Processing file: 58_S58_annotated.hg19_multianno.txt\n",
      "Processing file: 59_S59_annotated.hg19_multianno.txt\n",
      "Processing file: 5_S5_annotated.hg19_multianno.txt\n",
      "Processing file: 60_S60_annotated.hg19_multianno.txt\n",
      "Processing file: 61_S61_annotated.hg19_multianno.txt\n",
      "Processing file: 62_S62_annotated.hg19_multianno.txt\n",
      "Processing file: 63_S63_annotated.hg19_multianno.txt\n",
      "Processing file: 64_S64_annotated.hg19_multianno.txt\n",
      "Processing file: 65_S65_annotated.hg19_multianno.txt\n",
      "Processing file: 66_S66_annotated.hg19_multianno.txt\n",
      "Processing file: 67_S67_annotated.hg19_multianno.txt\n",
      "Processing file: 68_S68_annotated.hg19_multianno.txt\n",
      "Processing file: 69_S69_annotated.hg19_multianno.txt\n",
      "Processing file: 6_S6_annotated.hg19_multianno.txt\n",
      "Processing file: 70_S70_annotated.hg19_multianno.txt\n",
      "Processing file: 71_S71_annotated.hg19_multianno.txt\n",
      "Processing file: 73_S72_annotated.hg19_multianno.txt\n",
      "Processing file: 74_S73_annotated.hg19_multianno.txt\n",
      "Processing file: 75_S74_annotated.hg19_multianno.txt\n",
      "Processing file: 76_S75_annotated.hg19_multianno.txt\n",
      "Processing file: 77_S76_annotated.hg19_multianno.txt\n",
      "Processing file: 78_S77_annotated.hg19_multianno.txt\n",
      "Processing file: 79_S78_annotated.hg19_multianno.txt\n",
      "Processing file: 7_S7_annotated.hg19_multianno.txt\n",
      "Processing file: 80_S79_annotated.hg19_multianno.txt\n",
      "Processing file: 81_S80_annotated.hg19_multianno.txt\n",
      "Processing file: 82_S81_annotated.hg19_multianno.txt\n",
      "Processing file: 83_S82_annotated.hg19_multianno.txt\n",
      "Processing file: 84_S83_annotated.hg19_multianno.txt\n",
      "Processing file: 85_S84_annotated.hg19_multianno.txt\n",
      "Processing file: 86_S85_annotated.hg19_multianno.txt\n",
      "Processing file: 87_S86_annotated.hg19_multianno.txt\n",
      "Processing file: 88_S87_annotated.hg19_multianno.txt\n",
      "Processing file: 89_S88_annotated.hg19_multianno.txt\n",
      "Processing file: 8_S8_annotated.hg19_multianno.txt\n",
      "Processing file: 90_S89_annotated.hg19_multianno.txt\n",
      "Processing file: 91_S90_annotated.hg19_multianno.txt\n",
      "Processing file: 92_S91_annotated.hg19_multianno.txt\n",
      "Processing file: 94_S92_annotated.hg19_multianno.txt\n",
      "Processing file: 95_S93_annotated.hg19_multianno.txt\n",
      "Processing file: 96_S94_annotated.hg19_multianno.txt\n",
      "Processing file: 9_S9_annotated.hg19_multianno.txt\n",
      "Processing file: A01_S1_annotated.hg19_multianno.txt\n",
      "Processing file: A02_S2_annotated.hg19_multianno.txt\n",
      "Processing file: A03_S3_annotated.hg19_multianno.txt\n",
      "Processing file: A04_S4_annotated.hg19_multianno.txt\n",
      "Processing file: Undetermined_S0_annotated.hg19_multianno.txt\n",
      "Combined CSV written with shape: (32286, 106)\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "folder = Path(\"C:/Users/LENOVO/Documents/ONCO50_PMS2_REANALYSIS/output\")\n",
    "\n",
    "dfs = []\n",
    "for f in folder.glob(\"*txt\"):\n",
    "    if f.is_file():\n",
    "        print(f\"Processing file: {f.name}\")\n",
    "        df = pd.read_csv(f, sep=\"\\t\", dtype=str)\n",
    "        match = re.match(r\"(\\d+)_\", f.name)\n",
    "        file_id = match.group(1) if match else f.stem.split(\"_\")[0]\n",
    "        df.insert(0, \"ID\", file_id)\n",
    "        dfs.append(df)\n",
    "\n",
    "if dfs:\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    combined.to_csv(\"combined.csv\", index=False)\n",
    "    print(f\"Combined CSV written with shape: {combined.shape}\")\n",
    "else:\n",
    "    print(\"No .txt files found in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626e96a5-1161-4433-b60b-63fd6e485ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c18063",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combining normalized vcf files into a combined vcf. Annovar scattered the \n",
    "# orientation of the reference and alternate alleles, using the normalized to replace\n",
    "#reference and alternate alleles in the final csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795135ec-a4a0-4da1-8dd4-3824051186f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zipped VCF: 10_S7_normalized.vcf.gz\n",
      "Processing zipped VCF: 11_S8_normalized.vcf.gz\n",
      "Processing zipped VCF: 12_S9_normalized.vcf.gz\n",
      "Processing zipped VCF: 13_S10_normalized.vcf.gz\n",
      "Processing zipped VCF: 14_S11_normalized.vcf.gz\n",
      "Processing zipped VCF: 15_S12_normalized.vcf.gz\n",
      "Processing zipped VCF: 17_S13_normalized.vcf.gz\n",
      "Processing zipped VCF: 18_S14_normalized.vcf.gz\n",
      "Processing zipped VCF: 19_S15_normalized.vcf.gz\n",
      "Processing zipped VCF: 20_S16_normalized.vcf.gz\n",
      "Processing zipped VCF: 21_S17_normalized.vcf.gz\n",
      "Processing zipped VCF: 22_S18_normalized.vcf.gz\n",
      "Processing zipped VCF: 23_S19_normalized.vcf.gz\n",
      "Processing zipped VCF: 24_S20_normalized.vcf.gz\n",
      "Processing zipped VCF: 25_S21_normalized.vcf.gz\n",
      "Processing zipped VCF: 27_S22_normalized.vcf.gz\n",
      "Processing zipped VCF: 28_S23_normalized.vcf.gz\n",
      "Processing zipped VCF: 29_S24_normalized.vcf.gz\n",
      "Processing zipped VCF: 2_S1_normalized.vcf.gz\n",
      "Processing zipped VCF: 30_S25_normalized.vcf.gz\n",
      "Processing zipped VCF: 31_S26_normalized.vcf.gz\n",
      "Processing zipped VCF: 32_S27_normalized.vcf.gz\n",
      "Processing zipped VCF: 33_S28_normalized.vcf.gz\n",
      "Processing zipped VCF: 34_S29_normalized.vcf.gz\n",
      "Processing zipped VCF: 35_S30_normalized.vcf.gz\n",
      "Processing zipped VCF: 36_S31_normalized.vcf.gz\n",
      "Processing zipped VCF: 37_S32_normalized.vcf.gz\n",
      "Processing zipped VCF: 38_S33_normalized.vcf.gz\n",
      "Processing zipped VCF: 39_S34_normalized.vcf.gz\n",
      "Processing zipped VCF: 40_S35_normalized.vcf.gz\n",
      "Processing zipped VCF: 41_S36_normalized.vcf.gz\n",
      "Processing zipped VCF: 42_S37_normalized.vcf.gz\n",
      "Processing zipped VCF: 43_S38_normalized.vcf.gz\n",
      "Processing zipped VCF: 44_S39_normalized.vcf.gz\n",
      "Processing zipped VCF: 45_S40_normalized.vcf.gz\n",
      "Processing zipped VCF: 46_S41_normalized.vcf.gz\n",
      "Processing zipped VCF: 47_S42_normalized.vcf.gz\n",
      "Processing zipped VCF: 48_S43_normalized.vcf.gz\n",
      "Processing zipped VCF: 49_S44_normalized.vcf.gz\n",
      "Processing zipped VCF: 51_S45_normalized.vcf.gz\n",
      "Processing zipped VCF: 52_S46_normalized.vcf.gz\n",
      "Processing zipped VCF: 53_S47_normalized.vcf.gz\n",
      "Processing zipped VCF: 54_S48_normalized.vcf.gz\n",
      "Processing zipped VCF: 56_S49_normalized.vcf.gz\n",
      "Processing zipped VCF: 57_S50_normalized.vcf.gz\n",
      "Processing zipped VCF: 58_S51_normalized.vcf.gz\n",
      "Processing zipped VCF: 59_S52_normalized.vcf.gz\n",
      "Processing zipped VCF: 5_S2_normalized.vcf.gz\n",
      "Processing zipped VCF: 60_S53_normalized.vcf.gz\n",
      "Processing zipped VCF: 61_S54_normalized.vcf.gz\n",
      "Processing zipped VCF: 62_S55_normalized.vcf.gz\n",
      "Processing zipped VCF: 63_S56_normalized.vcf.gz\n",
      "Processing zipped VCF: 64_S57_normalized.vcf.gz\n",
      "Processing zipped VCF: 65_S58_normalized.vcf.gz\n",
      "Processing zipped VCF: 66_S59_normalized.vcf.gz\n",
      "Processing zipped VCF: 67_S60_normalized.vcf.gz\n",
      "Processing zipped VCF: 68_S61_normalized.vcf.gz\n",
      "Processing zipped VCF: 69_S62_normalized.vcf.gz\n",
      "Processing zipped VCF: 6_S3_normalized.vcf.gz\n",
      "Processing zipped VCF: 70_S63_normalized.vcf.gz\n",
      "Processing zipped VCF: 72_S64_normalized.vcf.gz\n",
      "Processing zipped VCF: 73_S65_normalized.vcf.gz\n",
      "Processing zipped VCF: 74_S66_normalized.vcf.gz\n",
      "Processing zipped VCF: 75_S67_normalized.vcf.gz\n",
      "Processing zipped VCF: 76_S68_normalized.vcf.gz\n",
      "Processing zipped VCF: 77_S69_normalized.vcf.gz\n",
      "Processing zipped VCF: 78_S70_normalized.vcf.gz\n",
      "Processing zipped VCF: 79_S71_normalized.vcf.gz\n",
      "Processing zipped VCF: 7_S4_normalized.vcf.gz\n",
      "Processing zipped VCF: 80_S72_normalized.vcf.gz\n",
      "Processing zipped VCF: 81_S73_normalized.vcf.gz\n",
      "Processing zipped VCF: 82_S74_normalized.vcf.gz\n",
      "Processing zipped VCF: 83_S75_normalized.vcf.gz\n",
      "Processing zipped VCF: 84_S76_normalized.vcf.gz\n",
      "Processing zipped VCF: 85_S77_normalized.vcf.gz\n",
      "Processing zipped VCF: 86_S78_normalized.vcf.gz\n",
      "Processing zipped VCF: 87_S79_normalized.vcf.gz\n",
      "Processing zipped VCF: 88_S80_normalized.vcf.gz\n",
      "Processing zipped VCF: 89_S81_normalized.vcf.gz\n",
      "Processing zipped VCF: 8_S5_normalized.vcf.gz\n",
      "Processing zipped VCF: 90_S82_normalized.vcf.gz\n",
      "Processing zipped VCF: 91_S83_normalized.vcf.gz\n",
      "Processing zipped VCF: 92_S84_normalized.vcf.gz\n",
      "Processing zipped VCF: 93_S85_normalized.vcf.gz\n",
      "Processing zipped VCF: 94_S86_normalized.vcf.gz\n",
      "Processing zipped VCF: 95_S87_normalized.vcf.gz\n",
      "Processing zipped VCF: 96_S88_normalized.vcf.gz\n",
      "Processing zipped VCF: 9_S6_normalized.vcf.gz\n",
      "Processing zipped VCF: Undetermined_S0_normalized.vcf.gz\n",
      "‚úÖ Combined zipped VCF saved to:\n",
      "C:\\Users\\LENOVO\\Documents\\ONCO50_PMS2_REANALYSIS\\output_03\\combined_Batch1vcf.csv\n",
      "Shape: (27651, 99)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import gzip\n",
    "import io\n",
    "\n",
    "folder = Path(\"C:/Users/LENOVO/Documents/ONCO50_PMS2_REANALYSIS/output_03\")\n",
    "\n",
    "vcf_dfs = []\n",
    "\n",
    "for f in folder.glob(\"*normalized.vcf.gz\"):\n",
    "    print(f\"Processing zipped VCF: {f.name}\")\n",
    "    \n",
    "    with gzip.open(f, \"rt\") as fh:\n",
    "        lines = [line for line in fh if not line.startswith(\"##\")]\n",
    "    \n",
    "    if not lines:\n",
    "        print(f\"‚ö†Ô∏è Skipping empty VCF: {f.name}\")\n",
    "        continue\n",
    "\n",
    "    header_line = next((line for line in lines if line.startswith(\"#CHROM\")), None)\n",
    "    data_lines = [line for line in lines if not line.startswith(\"#\")]\n",
    "\n",
    "    if header_line and data_lines:\n",
    "        columns = header_line.strip().lstrip(\"#\").split(\"\\t\")\n",
    "        vcf_df = pd.read_csv(io.StringIO(\"\".join(data_lines)), sep=\"\\t\", names=columns, dtype=str)\n",
    "        \n",
    "        # Extract sample ID from filename (e.g., 123_normalized.vcf.gz ‚Üí 123)\n",
    "        match = re.match(r\"(\\d+)_\", f.name)\n",
    "        file_id = match.group(1) if match else f.stem.split(\"_\")[0]\n",
    "        \n",
    "        vcf_df.insert(0, \"Sample_ID\", file_id)\n",
    "        vcf_dfs.append(vcf_df)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No usable content in: {f.name}\")\n",
    "\n",
    "# Save the combined VCF table\n",
    "if vcf_dfs:\n",
    "    combined_Batch1vcf = pd.concat(vcf_dfs, ignore_index=True)\n",
    "    out_path = folder / \"combined_Batch1vcf.csv\"\n",
    "    combined_Batch1vcf.to_csv(out_path, index=False)\n",
    "    print(f\"‚úÖ Combined zipped VCF saved to:\\n{out_path}\\nShape: {combined_Batch1vcf.shape}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid zipped VCF files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f3e94-3581-439a-aa15-0837bf3e387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Both merged batches have similar IDs so i need to change to original sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3934825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ID values replaced with names using mapping.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the main file with plate numbers\n",
    "main_df = pd.read_csv(\"C:/Users/LENOVO/Documents/ONCO50_PMS2_REANALYSIS/output_03/combined_1.csv\")\n",
    "\n",
    "# Load the mapping file that maps Plate_No to Sample_ID\n",
    "mapping_df = pd.read_csv(\"C:/Users/LENOVO/Documents/ONCO50/sample_name.csv\")\n",
    "\n",
    "# Create a dictionary: ID ‚Üí Name\n",
    "id_to_name = mapping_df.set_index(\"ID\")[\"NAME\"].to_dict()\n",
    "\n",
    "# Replace values in the main dataframe's ID column\n",
    "main_df[\"ID\"] = main_df[\"ID\"].map(id_to_name).fillna(main_df[\"ID\"])  # fallback if no match\n",
    "\n",
    "# Save result\n",
    "main_df.to_csv(\"vcf_with_named_ids.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ ID values replaced with names using mapping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158091cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Desktop\\Python_Learn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac92f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
